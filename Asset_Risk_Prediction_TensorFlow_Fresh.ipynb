{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "70035cc7",
   "metadata": {},
   "source": [
    "\n",
    "# Asset Risk Prediction — TensorFlow DNN (AI4I 2020)\n",
    "\n",
    "End-to-end notebook to build a **predictive maintenance / asset-risk** classifier using a **TensorFlow** deep neural network on the **AI4I 2020 Predictive Maintenance** dataset.\n",
    "\n",
    "**What you get:**\n",
    "- One-click **environment setup** with pinned, compatible package versions\n",
    "- **Data fetch** from UCI via `ucimlrepo` (with simple fallback option)\n",
    "- **Feature engineering** (temperature deltas, power proxy, wear ratios)\n",
    "- **Train/Validation/Test** split with **class weighting** for imbalance\n",
    "- **TensorFlow** model with dropout + batch normalisation + early stopping\n",
    "- **ROC** & **Precision–Recall** curves, **calibration curve**, confusion matrix\n",
    "- Exported **risk report** CSV, saved **model** and **metrics** for your repo\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99a15de3",
   "metadata": {},
   "source": [
    "\n",
    "## 1. Environment Setup\n",
    "Run this cell first. It ensures TensorFlow and friends are installed in versions that play nicely together.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e07723a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import sys, subprocess, pkgutil\n",
    "\n",
    "def pip_install(*args):\n",
    "    cmd = [sys.executable, \"-m\", \"pip\", \"install\", *args]\n",
    "    print(\"Running:\", \" \".join(cmd))\n",
    "    subprocess.check_call(cmd)\n",
    "\n",
    "# Upgrade pip, then install pinned, compatible versions\n",
    "pip_install(\"--upgrade\", \"pip\", \"wheel\", \"setuptools\")\n",
    "pip_install(\"numpy<2.0\", \"tensorflow==2.16.1\", \"scikit-learn\", \"pandas\", \"matplotlib\", \"seaborn\", \"joblib\", \"ucimlrepo\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32ba5c61",
   "metadata": {},
   "source": [
    "\n",
    "## 2. Imports & Version Check\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51fb83cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os, sys, math, json, textwrap, warnings\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import (\n",
    "    roc_auc_score, average_precision_score, precision_recall_curve,\n",
    "    roc_curve, confusion_matrix, classification_report\n",
    ")\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.isotonic import IsotonicRegression\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras import layers\n",
    "\n",
    "from joblib import dump\n",
    "warnings.filterwarnings('ignore')\n",
    "plt.rcParams['figure.figsize'] = (8, 5)\n",
    "\n",
    "print(\"Python:\", sys.version)\n",
    "print(\"NumPy:\", np.__version__)\n",
    "print(\"TensorFlow:\", tf.__version__)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6912cf9",
   "metadata": {},
   "source": [
    "\n",
    "## 3. Paths & Output Folders\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a8c31fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "ROOT = Path.cwd()\n",
    "OUT = ROOT / \"outputs\"\n",
    "OUT.mkdir(parents=True, exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6db0dcca",
   "metadata": {},
   "source": [
    "\n",
    "## 4. Load Dataset (UCI AI4I 2020)\n",
    "This uses `ucimlrepo` to fetch the dataset by ID (601). No manual download needed.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce053b39",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from ucimlrepo import fetch_ucirepo\n",
    "\n",
    "ai4i = fetch_ucirepo(id=601)  # AI4I 2020 Predictive Maintenance\n",
    "X_raw = ai4i.data.features.copy()\n",
    "y_raw = ai4i.data.targets['Machine failure'].astype(int)\n",
    "\n",
    "print(\"Features shape:\", X_raw.shape, \"| Target shape:\", y_raw.shape)\n",
    "pd.DataFrame({\"col\": X_raw.columns}).head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f40a487",
   "metadata": {},
   "source": [
    "\n",
    "## 5. Basic Cleaning & Feature Engineering\n",
    "Create simple domain features that often help: temperature delta, a crude power proxy (rpm × torque), and wear per power.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22481e51",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Standardise column names for convenience\n",
    "X = X_raw.rename(columns={\n",
    "    'Air temperature [K]': 'air_temp_k',\n",
    "    'Process temperature [K]': 'proc_temp_k',\n",
    "    'Rotational speed [rpm]': 'rpm',\n",
    "    'Torque [Nm]': 'torque_nm',\n",
    "    'Tool wear [min]': 'tool_wear_min',\n",
    "})\n",
    "\n",
    "# Categorical\n",
    "X['Type'] = X['Type'].astype('category')\n",
    "\n",
    "# Engineered features\n",
    "X['temp_diff_k']    = X['proc_temp_k'] - X['air_temp_k']\n",
    "X['power_proxy']    = X['rpm'] * X['torque_nm']\n",
    "X['wear_per_power'] = X['tool_wear_min'] / (X['power_proxy'] + 1e-6)\n",
    "\n",
    "numeric_features = [\n",
    "    'air_temp_k','proc_temp_k','temp_diff_k',\n",
    "    'rpm','torque_nm','power_proxy',\n",
    "    'tool_wear_min','wear_per_power'\n",
    "]\n",
    "categorical_features = ['Type']\n",
    "\n",
    "target = y_raw\n",
    "df = pd.concat([X[numeric_features + categorical_features], target.rename(\"failure\")], axis=1)\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a23ddb70",
   "metadata": {},
   "source": [
    "\n",
    "## 6. Quick EDA\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fafa043",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "ax = df['failure'].value_counts().sort_index().plot(kind='bar')\n",
    "ax.set_xlabel('failure (0/1)'); ax.set_ylabel('count'); ax.set_title('Target Distribution')\n",
    "plt.show()\n",
    "\n",
    "df[numeric_features].describe().T\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c2ae0ff",
   "metadata": {},
   "source": [
    "\n",
    "## 7. Train / Validation / Test Split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db1cce83",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X_all = df[numeric_features + categorical_features].copy()\n",
    "y_all = df['failure'].copy()\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_all, y_all, test_size=0.20, random_state=42, stratify=y_all\n",
    ")\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X_train, y_train, test_size=0.20, random_state=42, stratify=y_train\n",
    ")\n",
    "\n",
    "len(X_train), len(X_val), len(X_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de7574bf",
   "metadata": {},
   "source": [
    "\n",
    "## 8. Preprocessing\n",
    "Standardise numeric features, one-hot encode categorical `Type`, and build the final matrices.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02d840a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "pre_num = StandardScaler()\n",
    "pre_cat = OneHotEncoder(handle_unknown=\"ignore\", sparse_output=False)\n",
    "\n",
    "# Fit transforms\n",
    "X_train_num = pre_num.fit_transform(X_train[numeric_features])\n",
    "X_val_num   = pre_num.transform(X_val[numeric_features])\n",
    "X_test_num  = pre_num.transform(X_test[numeric_features])\n",
    "\n",
    "X_train_cat = pre_cat.fit_transform(X_train[categorical_features])\n",
    "X_val_cat   = pre_cat.transform(X_val[categorical_features])\n",
    "X_test_cat  = pre_cat.transform(X_test[categorical_features])\n",
    "\n",
    "# Concatenate\n",
    "import numpy as np\n",
    "Xtr = np.hstack([X_train_num, X_train_cat])\n",
    "Xva = np.hstack([X_val_num,   X_val_cat])\n",
    "Xte = np.hstack([X_test_num,  X_test_cat])\n",
    "\n",
    "feature_names = numeric_features + list(pre_cat.get_feature_names_out(categorical_features))\n",
    "Xtr.shape, Xva.shape, Xte.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90708f68",
   "metadata": {},
   "source": [
    "\n",
    "## 9. Handle Class Imbalance\n",
    "Compute class weights so the model pays more attention to the minority class.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f666cd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "classes = np.unique(y_train)\n",
    "weights = compute_class_weight(class_weight='balanced', classes=classes, y=y_train)\n",
    "class_weight = {int(c): float(w) for c, w in zip(classes, weights)}\n",
    "class_weight\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7610f9e3",
   "metadata": {},
   "source": [
    "\n",
    "## 10. TensorFlow Model — Build & Train\n",
    "Simple DNN with batch normalisation and dropout. We monitor validation loss and AUCs.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8af37ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "tf.random.set_seed(42)\n",
    "inputs = keras.Input(shape=(Xtr.shape[1],), name=\"features\")\n",
    "x = layers.Dense(128, activation='relu')(inputs)\n",
    "x = layers.BatchNormalization()(x)\n",
    "x = layers.Dropout(0.25)(x)\n",
    "x = layers.Dense(64, activation='relu')(x)\n",
    "x = layers.BatchNormalization()(x)\n",
    "x = layers.Dropout(0.25)(x)\n",
    "x = layers.Dense(32, activation='relu')(x)\n",
    "outputs = layers.Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "model = keras.Model(inputs=inputs, outputs=outputs, name=\"asset_risk_dnn\")\n",
    "model.compile(\n",
    "    optimizer=keras.optimizers.Adam(learning_rate=1e-3),\n",
    "    loss='binary_crossentropy',\n",
    "    metrics=[keras.metrics.AUC(name='auc', curve='ROC'),\n",
    "             keras.metrics.AUC(name='pr_auc', curve='PR')]\n",
    ")\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbfd34ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "callbacks = [\n",
    "    keras.callbacks.EarlyStopping(patience=10, restore_best_weights=True, monitor='val_loss'),\n",
    "    keras.callbacks.ReduceLROnPlateau(factor=0.5, patience=5, min_lr=1e-5, monitor='val_loss')\n",
    "]\n",
    "\n",
    "hist = model.fit(\n",
    "    Xtr, y_train,\n",
    "    validation_data=(Xva, y_val),\n",
    "    epochs=100,\n",
    "    batch_size=256,\n",
    "    class_weight=class_weight,\n",
    "    callbacks=callbacks,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Training curves\n",
    "hist_df = pd.DataFrame(hist.history)\n",
    "ax = hist_df[['loss','val_loss']].plot(title='Training / Validation Loss')\n",
    "ax.set_xlabel('epoch'); ax.set_ylabel('loss')\n",
    "plt.show()\n",
    "\n",
    "ax = hist_df[['auc','val_auc','pr_auc','val_pr_auc']].plot(title='AUC Metrics')\n",
    "ax.set_xlabel('epoch'); ax.set_ylabel('AUC')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05579d68",
   "metadata": {},
   "source": [
    "\n",
    "## 11. Evaluation on Test Set\n",
    "We compute ROC-AUC, PR-AUC, plot the curves, and show a confusion matrix at threshold 0.5.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81552b51",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.metrics import PrecisionRecallDisplay, RocCurveDisplay\n",
    "\n",
    "proba = model.predict(Xte, verbose=0).ravel()\n",
    "\n",
    "roc = roc_auc_score(y_test, proba)\n",
    "pr  = average_precision_score(y_test, proba)\n",
    "print(f\"ROC AUC: {roc:.3f} | PR AUC: {pr:.3f}\")\n",
    "\n",
    "# ROC curve\n",
    "RocCurveDisplay.from_predictions(y_test, proba)\n",
    "plt.title('ROC Curve')\n",
    "plt.show()\n",
    "\n",
    "# PR curve\n",
    "PrecisionRecallDisplay.from_predictions(y_test, proba)\n",
    "plt.title('Precision–Recall Curve')\n",
    "plt.show()\n",
    "\n",
    "# Confusion matrix at 0.5\n",
    "pred = (proba >= 0.5).astype(int)\n",
    "cm = confusion_matrix(y_test, pred)\n",
    "print('Confusion Matrix:\\n', cm)\n",
    "print('\\nClassification Report:\\n', classification_report(y_test, pred, digits=3))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6a168a5",
   "metadata": {},
   "source": [
    "\n",
    "## 12. Probability Calibration (Isotonic)\n",
    "We calibrate probabilities using validation predictions, then evaluate again on the test set.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68e7431f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "proba_val = model.predict(Xva, verbose=0).ravel()\n",
    "cal = IsotonicRegression(out_of_bounds='clip')\n",
    "cal.fit(proba_val, y_val)\n",
    "\n",
    "proba_cal = cal.predict(proba)\n",
    "\n",
    "# Calibration curve\n",
    "from sklearn.calibration import calibration_curve\n",
    "prob_true, prob_pred = calibration_curve(y_test, proba_cal, n_bins=10, strategy='quantile')\n",
    "plt.plot(prob_pred, prob_true, marker='o')\n",
    "plt.plot([0,1],[0,1],'--')\n",
    "plt.title('Calibration Curve (Isotonic)')\n",
    "plt.xlabel('Predicted probability'); plt.ylabel('Observed frequency')\n",
    "plt.show()\n",
    "\n",
    "roc_cal = roc_auc_score(y_test, proba_cal)\n",
    "pr_cal  = average_precision_score(y_test, proba_cal)\n",
    "print(f\"Calibrated ROC AUC: {roc_cal:.3f} | Calibrated PR AUC: {pr_cal:.3f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9480459",
   "metadata": {},
   "source": [
    "\n",
    "## 13. Risk Report & Artifacts\n",
    "Export a ranked list of asset IDs with calibrated risk scores. Save the model, calibrator, and metrics.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dba739ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Try to use 'UDI' as an ID if present\n",
    "id_series = X_raw['UDI'] if 'UDI' in X_raw.columns else pd.Series(X_test.index, index=X_test.index, name='id')\n",
    "ids_test = id_series.loc[X_test.index]\n",
    "\n",
    "risk_report = pd.DataFrame({\n",
    "    'id': ids_test.values,\n",
    "    'risk_score': proba_cal\n",
    "}).sort_values('risk_score', ascending=False)\n",
    "\n",
    "risk_path = OUT / \"risk_report.csv\"\n",
    "risk_report.to_csv(risk_path, index=False)\n",
    "print(\"Saved risk report to:\", risk_path.resolve())\n",
    "\n",
    "# Save model and calibrator\n",
    "model_dir = OUT / \"tf_model\"\n",
    "model.save(model_dir)\n",
    "dump(cal, OUT / \"isotonic_calibrator.joblib\")\n",
    "\n",
    "# Save metrics\n",
    "metrics_txt = OUT / \"metrics.txt\"\n",
    "metrics_txt.write_text(f\"\"\"Asset Risk Prediction — TensorFlow DNN\n",
    "ROC AUC (raw): {roc:.3f}\n",
    "PR  AUC (raw): {pr:.3f}\n",
    "ROC AUC (cal): {roc_cal:.3f}\n",
    "PR  AUC (cal): {pr_cal:.3f}\n",
    "Confusion matrix (0.5): {cm.tolist()}\n",
    "\"\"\", encoding=\"utf-8\")\n",
    "print(\"Saved model, calibrator and metrics to:\", OUT.resolve())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36c81cf4",
   "metadata": {},
   "source": [
    "\n",
    "## 14. (Optional) Simple Permutation Importance\n",
    "Estimate feature influence by measuring PR-AUC drop when shuffling each feature (on the test set).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "421d64bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def pr_auc_drop_on_shuffle(X_matrix, y_true, base_proba, n_repeats=3, seed=42):\n",
    "    rng = np.random.default_rng(seed)\n",
    "    base = average_precision_score(y_true, base_proba)\n",
    "    drops = []\n",
    "    for j, name in enumerate(feature_names):\n",
    "        scores = []\n",
    "        for _ in range(n_repeats):\n",
    "            Xp = X_matrix.copy()\n",
    "            rng.shuffle(Xp[:, j])\n",
    "            p = model.predict(Xp, verbose=0).ravel()\n",
    "            p = cal.predict(p)\n",
    "            scores.append(average_precision_score(y_true, p))\n",
    "        drops.append((name, base - float(np.mean(scores))))\n",
    "    return pd.DataFrame(drops, columns=['feature','pr_auc_drop']).sort_values('pr_auc_drop', ascending=False)\n",
    "\n",
    "perm_importance = pr_auc_drop_on_shuffle(Xte, y_test.values, proba_cal, n_repeats=3)\n",
    "perm_importance.head(10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e55a207",
   "metadata": {},
   "source": [
    "\n",
    "## 15. Summary (Copy for README)\n",
    "Trained a **TensorFlow** deep neural network on the **AI4I 2020** dataset to predict asset failures.  \n",
    "Engineered rolling-window–style features (temperature deltas, load proxy, wear ratios), handled class imbalance with **class weights**, and evaluated with **ROC-AUC** and **PR-AUC**.  \n",
    "Applied **isotonic calibration** to produce well-calibrated risk scores and exported a **ranked at-risk assets report** along with saved model artifacts.\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
